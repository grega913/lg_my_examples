{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create map-reduce branches for parallel \n",
    "\n",
    "This guide assumes familiarity with the following:\n",
    "\n",
    "*   LangGraph Glossary\n",
    "*   Send API\n",
    "*   Chat Models\n",
    "*   Structured Output\n",
    "\n",
    "Map-reduce operations are essential for efficient task decomposition and parallel processing. This approach involves breaking a task into smaller sub-tasks, processing each sub-task in parallel, and aggregating the results across all of the completed sub-tasks.\n",
    "\n",
    "Consider this example: given a general topic from the user, generate a list of related subjects, generate a joke for each subject, and select the best joke from the resulting list. In this design pattern, a first node may generate a list of objects (e.g., related subjects) and we want to apply some other node (e.g., generate a joke) to all those objects (e.g., subjects). However, two main challenges arise.\n",
    "\n",
    "(1) the number of objects (e.g., subjects) may be unknown ahead of time (meaning the number of edges may not be known) when we lay out the graph and (2) the input State to the downstream Node should be different (one for each generated object).\n",
    "\n",
    "LangGraph addresses these challenges through its Send API. By utilizing conditional edges, Send can distribute different states (e.g., subjects) to multiple instances of a node (e.g., joke generation). Importantly, the sent state can differ from the core graph's state, allowing for flexible and dynamic workflow management.\n",
    "\n",
    "\n",
    "error at last step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Model and prompts\n",
    "# Define model and prompts we will use\n",
    "subjects_prompt = \"\"\"Generate a comma separated list of between 2 and 5 examples related to: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one.\n",
    "\n",
    "{jokes}\"\"\"\n",
    "\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int = Field(description=\"Index of the best joke, starting with 0\", ge=0)\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "\n",
    "# Graph components: define the components that will make up the graph\n",
    "\n",
    "\n",
    "# This will be the overall state of the main graph.\n",
    "# It will contain a topic (which we expect the user to provide)\n",
    "# and then will generate a list of subjects, and then a joke for\n",
    "# each subject\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    # Notice here we use the operator.add\n",
    "    # This is because we want combine all the jokes we generate\n",
    "    # from individual nodes back into one list - this is essentially\n",
    "    # the \"reduce\" part\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str\n",
    "\n",
    "\n",
    "# This will be the state of the node that we will \"map\" all\n",
    "# subjects to in order to generate a joke\n",
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "\n",
    "# This is the function we will use to generate the subjects of the jokes\n",
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    return {\"subjects\": response.subjects}\n",
    "\n",
    "\n",
    "# Here we generate a joke, given a subject\n",
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}\n",
    "\n",
    "\n",
    "# Here we define the logic to map out over the generated subjects\n",
    "# We will use this as an edge in the graph\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    # We will return a list of `Send` objects\n",
    "    # Each `Send` object consists of the name of a node in the graph\n",
    "    # as well as the state to send to that node\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]\n",
    "\n",
    "\n",
    "# Here we will judge the best joke\n",
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}\n",
    "\n",
    "\n",
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"best_joke\", best_joke)\n",
    "\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n",
    "graph.add_edge(\"generate_joke\", \"best_joke\")\n",
    "graph.add_edge(\"best_joke\", END)\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_topics': {'subjects': ['elephant', 'tiger', 'dolphin', 'penguin', 'giraffe']}}\n",
      "{'generate_joke': {'jokes': ['Why don’t penguins like talking to strangers at parties? \\n\\nBecause they find it hard to break the ice!']}}\n",
      "{'generate_joke': {'jokes': [\"Why do elephants never use computers? Because they're afraid of the mouse!\"]}}\n",
      "{'generate_joke': {'jokes': ['Why did the dolphin bring a towel to the party? \\n\\nBecause it wanted to have a whale of a time!']}}\n",
      "{'generate_joke': {'jokes': ['Why did the tiger eat the tightrope walker?  \\nBecause he wanted a well-balanced meal!']}}\n",
      "{'generate_joke': {'jokes': [\"Why don't giraffes like fast food? \\n\\nBecause they can't catch it!\"]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:410: UserWarning: Invalid schema for OpenAI's structured output feature, which is the default method for `with_structured_output` as of langchain-openai==0.3. Specify `method=\"function_calling\"` instead or update your schema. See supported schemas: https://platform.openai.com/docs/guides/structured-outputs#supported-schemas\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'BestJoke': In context=('properties', 'id'), 'minimum' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Call the graph: here we call it to generate a list of jokes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manimals\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2331\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2325\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2326\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2327\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2328\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2329\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2331\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2338\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    144\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m config = patch_config(\n\u001b[32m    603\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mbest_joke\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     84\u001b[39m jokes = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(state[\u001b[33m\"\u001b[39m\u001b[33mjokes\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     85\u001b[39m prompt = best_joke_prompt.format(topic=state[\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m], jokes=jokes)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBestJoke\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mbest_selected_joke\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mjokes\u001b[39m\u001b[33m\"\u001b[39m][response.id]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5358\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5353\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5354\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5355\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5356\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5357\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5359\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5360\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5361\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5362\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:903\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    901\u001b[39m         response = \u001b[38;5;28mself\u001b[39m.root_client.beta.chat.completions.parse(**payload)\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43m_handle_openai_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_responses_api(payload):\n\u001b[32m    905\u001b[39m     original_schema_obj = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:411\u001b[39m, in \u001b[36m_handle_openai_bad_request\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    403\u001b[39m     message = (\n\u001b[32m    404\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid schema for OpenAI\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms structured output feature, which is the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    405\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdefault method for `with_structured_output` as of langchain-openai==0.3. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://platform.openai.com/docs/guides/structured-outputs#supported-schemas\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    409\u001b[39m     )\n\u001b[32m    410\u001b[39m     warnings.warn(message)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:901\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    899\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    903\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gs\\Documents\\AI24\\LangChain_202409\\lg_my_examples\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'BestJoke': In context=('properties', 'id'), 'minimum' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
      "During task with name 'best_joke' and id '14898544-ed75-c36b-427b-17647296f423'"
     ]
    }
   ],
   "source": [
    "# Call the graph: here we call it to generate a list of jokes\n",
    "for s in graph.stream({\"topic\": \"animals\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
